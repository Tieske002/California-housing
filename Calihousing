# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import joblib

# Load the dataset
from sklearn.datasets import fetch_california_housing
housing = fetch_california_housing(as_frame=True)
df = housing.frame

# Show the first few rows
print(df.head())

# Split data into train and test sets
train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)

# Explore the data (just a quick look at correlations and histograms)
df.plot(kind="scatter", x="Longitude", y="Latitude", alpha=0.4,
        s=df["Population"]/100, label="Population", figsize=(10,7),
        c="MedHouseVal", cmap=plt.get_cmap("jet"), colorbar=True)
plt.legend()
plt.show()

# Visualize correlations
corr_matrix = df.corr()
print(corr_matrix["MedHouseVal"].sort_values(ascending=False))

# Prepare the data for Machine Learning
# Separate features and labels
housing = train_set.drop("MedHouseVal", axis=1)  # drop labels for training set
housing_labels = train_set["MedHouseVal"].copy()

# Create numerical and categorical attribute pipelines
numerical_features = list(housing.drop("OceanProximity", axis=1))
categorical_features = ["OceanProximity"]

# Numerical pipeline
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy="median")),
    ('scaler', StandardScaler()),
])

# Full pipeline (numerical + categorical)
full_pipeline = ColumnTransformer([
    ("num", num_pipeline, numerical_features),
    ("cat", OneHotEncoder(), categorical_features),
])

# Prepare the data (fit and transform)
housing_prepared = full_pipeline.fit_transform(housing)

# Try a few models
# 1. Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, housing_labels)

# 2. Decision Tree Regressor
tree_reg = DecisionTreeRegressor(random_state=42)
tree_reg.fit(housing_prepared, housing_labels)

# 3. Random Forest Regressor
forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)
forest_reg.fit(housing_prepared, housing_labels)

# Evaluate models using cross-validation
def display_scores(scores):
    print("Scores:", scores)
    print("Mean:", scores.mean())
    print("Standard deviation:", scores.std())

# Linear Regression cross-validation
lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, 
                             scoring="neg_mean_squared_error", cv=10)
lin_rmse_scores = np.sqrt(-lin_scores)
display_scores(lin_rmse_scores)

# Decision Tree cross-validation
tree_scores = cross_val_score(tree_reg, housing_prepared, housing_labels, 
                              scoring="neg_mean_squared_error", cv=10)
tree_rmse_scores = np.sqrt(-tree_scores)
display_scores(tree_rmse_scores)

# Random Forest cross-validation
forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels, 
                                scoring="neg_mean_squared_error", cv=10)
forest_rmse_scores = np.sqrt(-forest_scores)
display_scores(forest_rmse_scores)

# Fine-tuning the Random Forest using GridSearchCV
param_grid = [
    {'n_estimators': [50, 100, 150], 'max_features': [8, 10, 12]},
]

grid_search = GridSearchCV(forest_reg, param_grid, cv=5,
                           scoring='neg_mean_squared_error',
                           return_train_score=True)
grid_search.fit(housing_prepared, housing_labels)

print("Best hyperparameters:", grid_search.best_params_)

# Final Model Evaluation on Test Set
final_model = grid_search.best_estimator_

X_test = test_set.drop("MedHouseVal", axis=1)
y_test = test_set["MedHouseVal"].copy()

X_test_prepared = full_pipeline.transform(X_test)
final_predictions = final_model.predict(X_test_prepared)

final_mse = mean_squared_error(y_test, final_predictions)
final_rmse = np.sqrt(final_mse)
print("Final RMSE on test set:", final_rmse)

# Save the model
joblib.dump(final_model, "final_model.pkl")

